{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14f4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8cbe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'F:/downlolad2/11_model.pth'  # CHANGE THIS TO YOUR .pth file directory\n",
    "model = torch.load(PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0c3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder developed by Kata Kriszta Keresztesi \n",
    "class SymmetricConvAutoencoder(nn.Module):\n",
    "  def __init__(self, act_fn):\n",
    "        super(SymmetricConvAutoencoder, self).__init__()\n",
    "\n",
    "        self.act_fn = act_fn\n",
    "\n",
    "        # Encoding\n",
    "        self.enc1 = nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1)    # Output: 8x256x256\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.enc2 = nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1)   # Output: 16x128x128\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.enc3 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)  # Output: 32x64x64\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.enc4 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  # Output: 64x32x32\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.enc5 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1) # Output: 128x16x16\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.enc6 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1) # Output: 256x8x8\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.enc7 = nn.Linear(256 * 8 * 8, 2048)                            # Output: 2048\n",
    "        self.bn7 = nn.BatchNorm1d(2048)\n",
    "\n",
    "        # Decoding\n",
    "        self.dec1 = nn.Linear(2048, 256 * 8 * 8)                            # Output: 256x8x8 when reshaped\n",
    "        self.bn8 = nn.BatchNorm1d(256 * 8 * 8)\n",
    "\n",
    "        self.dec2 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1) # Output: 128x16x16\n",
    "        self.bn9 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.dec3 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: 64x32x32\n",
    "        self.bn10 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.dec4 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)   # Output: 32x64x64\n",
    "        self.bn11 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.dec5 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)   # Output: 16x128x128\n",
    "        self.bn12 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.dec6 = nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1)    # Output: 8x256x256\n",
    "        self.bn13 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.dec7 = nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1)     # Output: 1x512x512\n",
    "  def forward(self, x):\n",
    "    # Encoding\n",
    "        x1 = self.act_fn(self.bn1(self.enc1(x)))\n",
    "        x2 = self.act_fn(self.bn2(self.enc2(x1)))\n",
    "        x3 = self.act_fn(self.bn3(self.enc3(x2)))\n",
    "        x4 = self.act_fn(self.bn4(self.enc4(x3)))\n",
    "        x5 = self.act_fn(self.bn5(self.enc5(x4)))\n",
    "        x6 = self.act_fn(self.bn6(self.enc6(x5)))\n",
    "        x6_flat = x6.view(-1, 256 * 8 * 8)\n",
    "        x7 = self.act_fn(self.bn7(self.enc7(x6_flat)))\n",
    "\n",
    "        # Decoding\n",
    "        x6_d = self.act_fn(self.bn8(self.dec1(x7)))\n",
    "        x6_d = x6_d.view(-1, 256, 8, 8)\n",
    "        x5_d = self.act_fn(self.bn9(self.dec2(x6_d)))   # Skip connection from x6\n",
    "        x5_d = x5_d + x5\n",
    "        x4_d = self.act_fn(self.bn10(self.dec3(x5_d)))  # Skip connection from x5\n",
    "        x4_d = x4_d + x4\n",
    "        x3_d = self.act_fn(self.bn11(self.dec4(x4_d)))  # Skip connection from x4\n",
    "        x3_d = x3_d + x3\n",
    "        x2_d = self.act_fn(self.bn12(self.dec5(x3_d)))  # Skip connection from x3\n",
    "        x2_d = x2_d + x2\n",
    "        x1_d = self.act_fn(self.bn13(self.dec6(x2_d)))  # Skip connection from x2\n",
    "        x1_d = x1_d + x1\n",
    "        x_out = self.dec7(x1_d)\n",
    "\n",
    "\n",
    "        return x_out, x7   # This returns the final stuff and the bottleneck layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce211fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to F:/Uni Y3/tesi/botfeatimg/img/botfeatres.xlsx\n"
     ]
    }
   ],
   "source": [
    "#activation function\n",
    "act_fn = F.relu\n",
    "# instantiate the SymmetricConvAutoencoder model with activation function\n",
    "big_model = SymmetricConvAutoencoder(act_fn)\n",
    "# load the pre-trained state dictionary into the model\n",
    "big_model.load_state_dict(model)\n",
    "symConvAuto = big_model.to(torch.device('cpu'))\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "input_directory = 'F:/Uni Y3/tesi/botfeatimg/img'\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# iterate over all image files\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.png'):\n",
    "        image_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            image = transform(image)\n",
    "            \n",
    "            #set the model to evaluation mode\n",
    "            big_model.eval()\n",
    "            \n",
    "            #perform inference on the image using the model\n",
    "            reconstructed_pic, vector = symConvAuto(image.unsqueeze(0))\n",
    "           \n",
    "            #convert the vector to a list\n",
    "            vector_values = vector.squeeze().tolist()\n",
    "            \n",
    "            #add the vector values to the df with the filename as index\n",
    "            results_df[filename] = vector_values\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# transpose df to have filenames as rows and vector values as columns\n",
    "results_df = results_df.T\n",
    "\n",
    "output_excel_path = 'F:/Uni Y3/tesi/botfeatimg/img/botfeatres.xlsx'\n",
    "results_df.to_excel(output_excel_path)\n",
    "\n",
    "print(f\"Results saved to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb580c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
