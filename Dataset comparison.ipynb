{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "805e3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b772d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'F:/downlolad2/11_model.pth'  # CHANGE THIS TO YOUR .pth file directory\n",
    "model = torch.load(PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7211a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmetricConvAutoencoder(nn.Module):\n",
    "  def __init__(self, act_fn):\n",
    "        super(SymmetricConvAutoencoder, self).__init__()\n",
    "\n",
    "        self.act_fn = act_fn\n",
    "\n",
    "        # Encoding\n",
    "        self.enc1 = nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1)    # Output: 8x256x256\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.enc2 = nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1)   # Output: 16x128x128\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.enc3 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)  # Output: 32x64x64\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.enc4 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  # Output: 64x32x32\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.enc5 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1) # Output: 128x16x16\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.enc6 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1) # Output: 256x8x8\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.enc7 = nn.Linear(256 * 8 * 8, 2048)                            # Output: 2048\n",
    "        self.bn7 = nn.BatchNorm1d(2048)\n",
    "\n",
    "        # Decoding\n",
    "        self.dec1 = nn.Linear(2048, 256 * 8 * 8)                            # Output: 256x8x8 when reshaped\n",
    "        self.bn8 = nn.BatchNorm1d(256 * 8 * 8)\n",
    "\n",
    "        self.dec2 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1) # Output: 128x16x16\n",
    "        self.bn9 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.dec3 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)  # Output: 64x32x32\n",
    "        self.bn10 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.dec4 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)   # Output: 32x64x64\n",
    "        self.bn11 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.dec5 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)   # Output: 16x128x128\n",
    "        self.bn12 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.dec6 = nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1)    # Output: 8x256x256\n",
    "        self.bn13 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.dec7 = nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1)     # Output: 1x512x512\n",
    "  def forward(self, x):\n",
    "    # Encoding\n",
    "        x1 = self.act_fn(self.bn1(self.enc1(x)))\n",
    "        x2 = self.act_fn(self.bn2(self.enc2(x1)))\n",
    "        x3 = self.act_fn(self.bn3(self.enc3(x2)))\n",
    "        x4 = self.act_fn(self.bn4(self.enc4(x3)))\n",
    "        x5 = self.act_fn(self.bn5(self.enc5(x4)))\n",
    "        x6 = self.act_fn(self.bn6(self.enc6(x5)))\n",
    "        x6_flat = x6.view(-1, 256 * 8 * 8)\n",
    "        x7 = self.act_fn(self.bn7(self.enc7(x6_flat)))\n",
    "\n",
    "        # Decoding\n",
    "        x6_d = self.act_fn(self.bn8(self.dec1(x7)))\n",
    "        x6_d = x6_d.view(-1, 256, 8, 8)\n",
    "        x5_d = self.act_fn(self.bn9(self.dec2(x6_d)))   # Skip connection from x6\n",
    "        #x5_d = x5_d + x5\n",
    "        x4_d = self.act_fn(self.bn10(self.dec3(x5_d)))  # Skip connection from x5\n",
    "        #x4_d = x4_d + x4\n",
    "        x3_d = self.act_fn(self.bn11(self.dec4(x4_d)))  # Skip connection from x4\n",
    "        #x3_d = x3_d + x3\n",
    "        x2_d = self.act_fn(self.bn12(self.dec5(x3_d)))  # Skip connection from x3\n",
    "        #x2_d = x2_d + x2\n",
    "        x1_d = self.act_fn(self.bn13(self.dec6(x2_d)))  # Skip connection from x2\n",
    "        x1_d = x1_d + x1\n",
    "        x_out = self.dec7(x1_d)\n",
    "\n",
    "\n",
    "        return x_out, x7   # This returns the final stuff and the bottleneck layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37335de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_22416\\4256437668.py:70: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to F:/Uni Y3/tesi/Giesma/giesma.xlsx\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "from skimage.feature import match_template\n",
    "\n",
    "act_fn = F.relu\n",
    "big_model = SymmetricConvAutoencoder(act_fn)\n",
    "big_model.load_state_dict(model)\n",
    "symConvAuto = big_model.to(torch.device('cpu'))\n",
    "\n",
    "# transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "input_directory = 'F:/Uni Y3/tesi/Giesma'\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Filename', 'MSE', 'SSIM', 'PSNR', 'MAPE', 'FSIM'])\n",
    "\n",
    "def calculate_mse(original, reconstructed):\n",
    "    mse = np.mean((original - reconstructed) ** 2)\n",
    "    return mse\n",
    "\n",
    "def calculate_mape(original, reconstructed, epsilon=1e-10):\n",
    "    abs_diff = np.abs(original - reconstructed)\n",
    "    mape = np.mean(abs_diff / (original + epsilon)) * 100\n",
    "    return mape\n",
    "\n",
    "def calculate_fsim(original, reconstructed):\n",
    "    result = match_template(original, reconstructed)\n",
    "    fsim = np.max(result)\n",
    "    return fsim\n",
    "\n",
    "def calculate_ssim(original, reconstructed):\n",
    "    ssim_value = structural_similarity(original, reconstructed, data_range=reconstructed.max() - reconstructed.min())\n",
    "    return ssim_value\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.png'):\n",
    "        image_path = os.path.join(input_directory, filename)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            image = transform(image)\n",
    "            \n",
    "            big_model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                reconstructed_pic, _ = symConvAuto(image.unsqueeze(0))\n",
    "           \n",
    "            reconstructed_np = reconstructed_pic.squeeze().detach().numpy()\n",
    "            initial_np = image.squeeze().cpu().numpy()\n",
    "            \n",
    "            #calc metrics\n",
    "            mse = calculate_mse(initial_np, reconstructed_np)\n",
    "            ssim_value = calculate_ssim(initial_np, reconstructed_np)\n",
    "            psnr_value = peak_signal_noise_ratio(initial_np, reconstructed_np, data_range=reconstructed_np.max() - reconstructed_np.min())\n",
    "            mape = calculate_mape(initial_np, reconstructed_np)\n",
    "            fsim_value = calculate_fsim(initial_np, reconstructed_np)\n",
    "            \n",
    "            # append res\n",
    "            results_df = pd.concat([results_df, pd.DataFrame({\n",
    "                'Filename': [filename],\n",
    "                'MSE': [mse],\n",
    "                'SSIM': [ssim_value],\n",
    "                'PSNR': [psnr_value],\n",
    "            })], ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# calculate averages and append\n",
    "average_metrics = results_df.drop(columns=['Filename']).mean(axis=0)\n",
    "average_metrics['Filename'] = 'Average'\n",
    "results_df = pd.concat([results_df, pd.DataFrame(average_metrics).T], ignore_index=True)\n",
    "\n",
    "output_excel_path = 'F:/Uni Y3/tesi/Giesma/giesma.xlsx'\n",
    "results_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1e301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
